{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60a24803",
   "metadata": {},
   "source": [
    "# Lab 05. Regression and Clustering\n",
    "\n",
    "\n",
    "In this lab we will tackle two types of tasks: \n",
    "- Regression Competition\n",
    "- Clustering practice\n",
    "\n",
    "\n",
    "#### Evaluation\n",
    "\n",
    "Each task has its value, **15 points** in total. If you use some open-source code please make sure to include the url.\n",
    "\n",
    "#### How to submit\n",
    "- Name your file according to this convention: `2022_lab05_GroupNumber_Surname_Name.ipynb`, for example \n",
    "    - `2022_lab05_404_Sheipak_Sviat.ipynb`\n",
    "    - `2022_lab05_M106_Sheipak_Sviat.ipynb`\n",
    "- Attach your .ipynb to an email with topic `2022_lab05_GroupNumber_Surname_Name`\n",
    "- Send it to `cosmic.research.ml@yandex.ru`\n",
    "- Deadline is `2022-12-08 23:00:00 +03:00`\n",
    "\n",
    "#### The Data:\n",
    "- All the datasets you need are here: https://disk.yandex.ru/d/gqo8GmBMUBfRuw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bace413",
   "metadata": {},
   "source": [
    "## Part 1. Regression [7 points]\n",
    "\n",
    "The task is to predict a price of a house sold in California based on some description of a house. Some columns give some information on the house itself (number of bedrooms, short written summary and so on) and some describe the neighborhood (middleschoolscore, middleschooldistance).\n",
    "\n",
    "* Id column - `id`\n",
    "* Target column - `sold_price`\n",
    "* Scoring is `RMSE` - root mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262deada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7791fde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"housing_train.csv\")\n",
    "df_test = pd.read_csv(\"housing_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56a91cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['bathrooms', 'full_bathrooms', 'total_interior_livable_area', 'total_spaces', 'garage_spaces', \n",
    "                'elementary_school_score', 'elementary_school_distance', 'middle_school_score', 'middle_school_distance', \n",
    "                'high_school_score', 'high_school_distance', 'tax_assessed_value', 'listed_price', \n",
    "                'last_sold_price', 'year_built', 'annual_tax_amount']\n",
    "\n",
    "cat_cols = ['type', 'heating', 'cooling', 'parking', 'bedrooms', 'region',\n",
    "            'elementary_school', 'middle_school', 'high_school', 'flooring', \n",
    "            'heating_features', 'cooling_features', 'appliances_included', \n",
    "            'laundry_features', 'parking_features', 'city', 'zip', 'state', 'listed_on', 'last_sold_on']\n",
    "\n",
    "text_cols = ['address', 'summary',]\n",
    "target_cols = ['sold_price']\n",
    "id_cols = ['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185451da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num_df = df_train[numeric_cols].fillna(df_train[numeric_cols].mean(axis=0))\n",
    "test_num_df = df_test[numeric_cols].fillna(df_test[numeric_cols].mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb596905",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = train_num_df.values, df_train[target_cols].values\n",
    "X_test, Y_test = test_num_df.values, df_test[target_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea8a326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a455b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid = {\n",
    "    \"alpha\": np.logspace(-5, 3, 100)\n",
    "}\n",
    "\n",
    "lr_grid_searcher = GridSearchCV(Ridge(), lr_grid, cv=5, return_train_score=True, scoring=\"neg_root_mean_squared_error\")\n",
    "lr_grid_searcher.fit(X_train, Y_train)\n",
    "lr_grid_searcher.best_estimator_,lr_grid_searcher.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97af0001",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = lr_grid_searcher.best_estimator_\n",
    "best_model.fit(X_train, Y_train)\n",
    "\n",
    "test_preds = best_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(Y_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377c88b3",
   "metadata": {},
   "source": [
    "Get a score as low as possible:\n",
    "\n",
    "Table ref:\n",
    "```\n",
    "Score < 0.25 - 1 points\n",
    "Score < 0.24 - 2 points\n",
    "Score < 0.22 - 3 points\n",
    "Score < 0.21 - 5 points\n",
    "Score < 0.20 - 6 points\n",
    "Score < 0.18 - 7 points\n",
    "```\n",
    "\n",
    "Don't forget to use categorical and text features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c3dac9",
   "metadata": {},
   "source": [
    "**Task 1.1** [7 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f9ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a806b8e",
   "metadata": {},
   "source": [
    "## Part 2. Clustering [8 points]\n",
    "\n",
    "In this part we will try to analyze a dump of leaked passwords of internet users. It can be accessed here: https://github.com/ignis-sec/Pwdb-Public/tree/master/wordlists\n",
    "\n",
    "First kind reminder - if you see your password in this base, change it immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb85b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "with open(\"ignis-1M.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        words.append(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f3938b",
   "metadata": {},
   "source": [
    "To make it more simple, we'll use only first 3K of passwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a2cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.array(words[:3000]).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06421ab3",
   "metadata": {},
   "source": [
    "**Task 2.1 [0.5 point]**\n",
    "\n",
    "Let's start with calculating levenshtein distance between words in the dataset. Compute a `3000x3000` distance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2757faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pylev import levenshtein\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e08f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((words.shape[0], words.shape[0]))\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b161cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X.reshape(-1), rwidth=0.5)\n",
    "plt.xticks(np.arange(0, X.max() + 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c1182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X, cmap=\"Purples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18613bd",
   "metadata": {},
   "source": [
    "**Task 2.2 [1.5 point]** First algorithm we'll use is `DBSCAN`.\n",
    "\n",
    "We have to adjust two parameters:\n",
    "- `eps`\n",
    "- `min_samples`\n",
    "\n",
    "Grid-search these two parameters and report number and sizes of output clusters for every pair of parameters. \n",
    "\n",
    "**Note**: to define an appropriate space for each parameter remember what they mean and how they affect DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014cacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7893f8",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43992ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 3.0\n",
    "min_samples = 3\n",
    "\n",
    "db = DBSCAN(metric=\"precomputed\", min_samples=min_samples, eps=eps).fit(X)\n",
    "labels = db.labels_\n",
    "len(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea529922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf7a775",
   "metadata": {},
   "source": [
    "**Task 2.3 [1 point]** Choose a set of parameters that leads to 20-25 clusters.\n",
    "\n",
    "- Is there a cluster that is significantly larger than the others? \n",
    "- How would you describe these clusters, what kind of passwords they contain? \n",
    "\n",
    "Use small samples from each cluster and try to describe a relevant password pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b2159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414dff4b",
   "metadata": {},
   "source": [
    "**Task 2.4 [1 point]** \n",
    "\n",
    "Let's try to improve clustering by introducing a custome levenshtein distance. You might have noticed that there are some specific password generation patterns, like `qwerty -> qwerty123`.\n",
    "\n",
    "Classic levenshtein distance for these two passwords is 3. Try to define a custom levenshtein distance that would make these passwords closer.\n",
    "\n",
    "Feel free to experiment and create as complex levenshtein distance as you would like.\n",
    "\n",
    "Report new clustering, describe new clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d733043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install -U strsimpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aad154f",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8514bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strsimpy.weighted_levenshtein import WeightedLevenshtein\n",
    "\n",
    "\n",
    "def insertion_cost(char):\n",
    "    return 1.0\n",
    "\n",
    "\n",
    "def deletion_cost(char):\n",
    "    return 1.0\n",
    "\n",
    "\n",
    "def substitution_cost(char_a, char_b):\n",
    "    if (char_a, char_b) == ('t', 'r') or (char_a, char_b) == ('r', 't'):\n",
    "        return 0.5\n",
    "    return 1.0\n",
    "\n",
    "weighted_levenshtein = WeightedLevenshtein(\n",
    "    substitution_cost_fn=substitution_cost,\n",
    "    insertion_cost_fn=insertion_cost,\n",
    "    deletion_cost_fn=deletion_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f693ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(levenshtein('Stting1', 'String1'))\n",
    "print(weighted_levenshtein.distance('Stting1', 'String1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cfcf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6e360b",
   "metadata": {},
   "source": [
    "**Task 2.5 [1 point]** Hierarchical Agglomerative clustering\n",
    "\n",
    "It is time to draw some pictures. \n",
    "- apply agglomerative clustering algorithm to form 5-10 clusters\n",
    "- plot a dendrogram\n",
    "- describe output clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d55303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337dffc8",
   "metadata": {},
   "source": [
    "Compute dendrogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0024c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_X = # YOUR CODE HERE\n",
    "linkage = hierarchy.linkage(# YOUR CODE HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9607e17e",
   "metadata": {},
   "source": [
    "Plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da329a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364ed4c3",
   "metadata": {},
   "source": [
    "Compute clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fa7003",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = AgglomerativeClustering(# YOUR CODE HERE)\n",
    "labels = cluster.predict(# YOUR CODE HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eba9c5",
   "metadata": {},
   "source": [
    "Describe them in any form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3f6f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43daa62c",
   "metadata": {},
   "source": [
    "### K-Means\n",
    "This clustering algorithm doesn't work with precomputed distances, as it has to calculate centroids and measure distance from a centroid to every object.\n",
    "\n",
    "Thus, we need to map the dataset to some vector space. How? Embeddings of course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89845433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab33032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(gensim.downloader.info()['models'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed45ed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_embeddings = gensim.downloader.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ec21df",
   "metadata": {},
   "source": [
    "**Task 2.6 [1 point]** \n",
    "\n",
    "- Create two lists - for those passwords that can be embedded and for their embeddings correspondigly\n",
    "- How many passwords have embeddings? \n",
    "- Describe the passwords that have embeddings and those that don't. Give your reasoning why these groups are formed like this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01bbd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_w_embeddings = [#YOUR CODE HERE]\n",
    "embeddings = [#YOUR CODE HERE]\n",
    "\n",
    "assert len(words_w_embeddings) = len(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab65618c",
   "metadata": {},
   "source": [
    "**Task 2.7 [2 point]** K-MEANS\n",
    "\n",
    "- Run kmeans with different parameters, for every set of parameters report average in-class, out-class distance\n",
    "- Remember that k-means has stochasticity, thus two algorithms with same hyperparameters can give different results\n",
    "- Chose several (3-5) your favorite k-means versions, visualize clusters in 2D using PCA or TSNE\n",
    "- Describe what are the clusters that kmeans can detect\n",
    "- Are they different from DBSCAN? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d061a274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b8abcb",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc3e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_clusters = KMeans(n_clusters=3).fit_predict(embeddings)\n",
    "    \n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_words = pca.fit_transform(embeddings)\n",
    "\n",
    "plt.scatter(pca_words[:, 0], pca_words[:, 1])\n",
    "plt.title(\"UNCOLOURED passwords PCA\") # YOU HAVE TO PLOT IT WITH COLORS\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb7918c",
   "metadata": {},
   "source": [
    "**Task 2.8 [extra points]**\n",
    "\n",
    "Here are some ideas how to experiment:\n",
    "- compare performance of algorithms with levenshtein distance and embeddings\n",
    "- use algorithms that were mentioned in the lecture, but with no explanation. In this section write a brief description of an algorithm before applying it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44029ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv-kernel",
   "language": "python",
   "name": "local-venv-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
